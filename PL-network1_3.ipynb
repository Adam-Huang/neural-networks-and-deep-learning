{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重固彭亮network 1-3的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network.py实现的神经网络比较简单，调用起来只用两步：Network([784,30,10])和SGD 顺着这个看一下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 构造神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, sizes):\n",
    "    \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "    respective layers of the network.  For example, if the list\n",
    "    was [2, 3, 1] then it would be a three-layer network, with the\n",
    "    first layer containing 2 neurons, the second layer 3 neurons,\n",
    "    and the third layer 1 neuron.  The biases and weights for the\n",
    "    network are initialized randomly, using a Gaussian\n",
    "    distribution with mean 0, and variance 1.  Note that the first\n",
    "    layer is assumed to be an input layer, and by convention we\n",
    "    won't set any biases for those neurons, since biases are only\n",
    "    ever used in computing the outputs from later layers.\"\"\"\n",
    "    self.num_layers = len(sizes)\n",
    "    self.sizes = sizes\n",
    "    self.biases = [np.random.randn(y, 1) for y in sizes[1:]] ##除了输入层其他层都需要一个Biases\n",
    "    self.weights = [np.random.randn(y, x)\n",
    "                    for x, y in zip(sizes[:-1], sizes[1:])]  ## 分别生成（30,784）和（10，30）的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function randn:\n",
      "\n",
      "randn(...) method of mtrand.RandomState instance\n",
      "    randn(d0, d1, ..., dn)\n",
      "    \n",
      "    Return a sample (or samples) from the \"standard normal\" distribution.\n",
      "    \n",
      "    If positive, int_like or int-convertible arguments are provided,\n",
      "    `randn` generates an array of shape ``(d0, d1, ..., dn)``, filled\n",
      "    with random floats sampled from a univariate \"normal\" (Gaussian)\n",
      "    distribution of mean 0 and variance 1 (if any of the :math:`d_i` are\n",
      "    floats, they are first converted to integers by truncation). A single\n",
      "    float randomly sampled from the distribution is returned if no\n",
      "    argument is provided.\n",
      "    \n",
      "    This is a convenience function.  If you want an interface that takes a\n",
      "    tuple as the first argument, use `numpy.random.standard_normal` instead.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    d0, d1, ..., dn : int, optional\n",
      "        The dimensions of the returned array, should be all positive.\n",
      "        If no argument is given a single Python float is returned.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Z : ndarray or float\n",
      "        A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\n",
      "        the standard normal distribution, or a single such float if\n",
      "        no parameters were supplied.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    random.standard_normal : Similar, but takes a tuple as its argument.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    For random samples from :math:`N(\\mu, \\sigma^2)`, use:\n",
      "    \n",
      "    ``sigma * np.random.randn(...) + mu``\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.random.randn()\n",
      "    2.1923875335537315 #random\n",
      "    \n",
      "    Two-by-four array of samples from N(3, 6.25):\n",
      "    \n",
      "    >>> 2.5 * np.random.randn(2, 4) + 3\n",
      "    array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],  #random\n",
      "           [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]]) #random\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.random.randn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51348912, -1.21852393, -0.56293872]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65213249, -0.60574028],\n",
       "       [-0.6679294 , -0.20503991]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结论已经很明显了，np.random.randn(x,y)是用来生成一个x行y列的array；其值是从标准正态分布中搞到的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. 导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -本来导入的是cPickle库，python3之后就不用了，而且有所改变，可参考：\n",
    "#### https://blog.csdn.net/lanqiu5ge/article/details/25136909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "##gzip是自带的，针对python2 和python3也有所不同，具体的可看上一篇.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = gzip.open('E:/Git-repository/neural-networks-and-deep-learning/data/mnist.pkl.gz', 'rb')\n",
    "tr_d, va_d, te_d = pickle.load(f,encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python2和python3有关cPickly包的区别用法： https://blog.csdn.net/xiaojiajia007/article/details/53707180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "2\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "50000\n",
      "50000\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tr_d))\n",
    "print(len(tr_d))\n",
    "print(type(tr_d[0]))\n",
    "print(type(tr_d[1]))\n",
    "## tr_d是一个由两个numpy.ndarray类组成的元组\n",
    "print(len(tr_d[0]))\n",
    "print(len(tr_d[1]))\n",
    "print(type(tr_d[0][0]))\n",
    "print(type(tr_d[1][0]))\n",
    "##第0个tr_d存放的是50000个numpy.ndarray；第1个tr_d存放的是50000个numpy.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_d[0][0].shape) ##可以认为是一个元组吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "temp = np.reshape(tr_d[0][0],(784,1))##从一个行向量，转换成了列向量\n",
    "print(temp.shape)\n",
    "print(type(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(tr_d[0][0][:10])\n",
    "print(type(temp))\n",
    "print(temp[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...9) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((10, 1)) ##肯定是用来生成一个10行1列的全0列向量的呀\n",
    "    e[j] = 1.0            ##把指定位置为1\n",
    "    return e\n",
    "\n",
    "training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "training_data = list(zip(training_inputs, training_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -因为python2 和python3的区别，所以要加个list将数据转换一下\n",
    "#### https://blog.csdn.net/u012509485/article/details/78203784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 1, 4, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "temp = [1,2,3,4,5,6,7]\n",
    "random.shuffle(temp)  ##shuffle有“洗”是意思，这里为“打乱”\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-32b1d51ff17d>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-32b1d51ff17d>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    delta = self.cost_derivative(activations[-1], y) *     ##结果是一个[10]10行列向量，这就是最后一行的差\u001b[0m\n\u001b[0m                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def update_mini_batch(self, mini_batch, eta):\n",
    "    \"\"\"Update the network's weights and biases by applying\n",
    "    gradient descent using backpropagation to a single mini batch.\n",
    "    The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "    is the learning rate.\"\"\"\n",
    "    nabla_b = [np.zeros(b.shape) for b in self.biases]##biases = (30,10)\n",
    "    nabla_w = [np.zeros(w.shape) for w in self.weights]##weights =(（30,784）和（10，30）)\n",
    "    for x, y in mini_batch:##mini_batch是截取的一段数据，和training_data有一样的形状，分别是(784,1)和(10,1)\n",
    "        delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "        nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "    self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                   for w, nw in zip(self.weights, nabla_w)]\n",
    "    self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                   for b, nb in zip(self.biases, nabla_b)]\n",
    "    \n",
    "def backprop(self, x, y):\n",
    "    \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "    gradient for the cost function C_x.  ``nabla_b`` and\n",
    "    ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "    to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "    nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "    # feedforward\n",
    "    activation = x\n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    #x是一个784行1列的列向量，当做输入层的输出\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    for b, w in zip(self.biases, self.weights):\n",
    "        z = np.dot(w, activation)+b ##矩阵乘法，相加，能和b相加，肯定是（[30],[10]）的两个向量\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)#也是[30],[10]）的两个向量\n",
    "    # backward pass\n",
    "    delta = self.cost_derivative(activations[-1], y) * \\\n",
    "    ##结果是一个[10]10行列向量，这就是最后一行的差\n",
    "        sigmoid_prime(zs[-1])##就是求导的（sigmoid(z)*(1-sigmoid(z))）\n",
    "        \n",
    "    nabla_b[-1] = delta  ##根据下面的性质，可知，这是一个（10,1）的向量\n",
    "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())## 这是隐藏层的输出乘以权重，就是z对w的导数\n",
    "    # Note that the variable l in the loop below is used a little\n",
    "    # differently to the notation in Chapter 2 of the book.  Here,\n",
    "    # l = 1 means the last layer of neurons, l = 2 is the\n",
    "    # second-last layer, and so on.  It's a renumbering of the\n",
    "    # scheme in the book, used here to take advantage of the fact\n",
    "    # that Python can use negative indices in lists.\n",
    "    for l in range(2, self.num_layers):##从倒数第2层向前更新，因为有个\"-\"号\n",
    "        z = zs[-l]\n",
    "        sp = sigmoid_prime(z)\n",
    "        delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "    return (nabla_b, nabla_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-1.96191778  1.16883108  0.37254797]]\n",
      "[[-1.96191778]\n",
      " [ 1.16883108]\n",
      " [ 0.37254797]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## transpose()应该是转置的意思,应该是矩阵的运算函数，这个z到底是什么类型呢？\n",
    "temp = np.random.randn(1,3)\n",
    "print(type(temp))\n",
    "print(temp)\n",
    "print(temp.transpose())\n",
    "print(type(training_data[0][0][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 验证下numpy.ndarray这种矩阵在点乘和函数操作时候的变化\n",
    "## 1. 生成一个numpy.ndarray ，更过方法可参考百度\n",
    "data1 = [1,2,3]\n",
    "data_1 = np.array(data1)\n",
    "print(type(data_1))\n",
    "print(data_1.shape)\n",
    "data1_ = np.reshape(data_1,(3,1))\n",
    "print(type(data1_))\n",
    "print(data1_.shape)\n",
    "data1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14],\n",
       "       [32],\n",
       "       [50]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. 点乘的运算\n",
    "d1 = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "d_1 = np.array(d1)\n",
    "print(d_1)\n",
    "dot_1 = np.dot(d_1,data1_)\n",
    "##可见和矩阵的乘法是一样的嘛~\n",
    "dot_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73105858 0.88079708 0.95257413]\n",
      " [0.98201379 0.99330715 0.99752738]\n",
      " [0.99908895 0.99966465 0.99987661]]\n",
      "[[ 14]\n",
      " [ 64]\n",
      " [150]]\n",
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "## 3. 带入函数以及普通的*（乘法）\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "s_1 = sigmoid(d_1)\n",
    "print(s_1)\n",
    "c_1 = dot_1* data1_\n",
    "print(c_1)\n",
    "s_2 = d_1 + data1_\n",
    "print(s_2)\n",
    "## 小结\n",
    "#矩阵的一般运算（函数呀，加乘呀）都是针对每个元素分别进行的\n",
    "# 需要注意3x3矩阵加3x1矩阵的情况哦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "cmd": "Other",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "cls": "KernelMagics",
        "colors": "BasicMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "copy": "Other",
        "ddir": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "echo": "Other",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "profile": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "ren": "Other",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %colors  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %matplotlib  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src import network2\n",
    "from src import mnist_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##导数数据和reshape都是一样的就不看了，首先来看看网络构造函数的不同：\n",
    "net = network2.Network([784,30,10],cost=network2.CrossEntropyCost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1 解析这个构造函数：关注：除以np.sqrt(30)就能将方差缩小嘛？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4] [1.         1.41421356 1.73205081 2.        ]\n",
      "[[1 2]\n",
      " [1 1]\n",
      " [2 2]]\n",
      "[[1.         1.41421356]\n",
      " [1.         1.        ]\n",
      " [1.41421356 1.41421356]] 5.477225575051661\n"
     ]
    }
   ],
   "source": [
    "## 首先调用了default_weight_initializer初始化权重self.default_weight_initializer()\n",
    "### np.sqrt\n",
    "import numpy as np\n",
    "x = [1,2,3,4]\n",
    "x1 = np.array(x)\n",
    "print(x1,np.sqrt(x1)) ##np.sqrt(x) ： 计算数组各元素的平方根\n",
    "x = [[1,2],[1,1],[2,2]]\n",
    "x1 = np.array(x)\n",
    "print(x1)\n",
    "print(np.sqrt(x1),np.sqrt(30))\n",
    "#小结：生成一个标准正态分布之后再除以sqrt(30)，相当于把x轴压缩了，所以可以近似为减少方差的正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2-2 network2.py中有一个save和load函数，是用来保存参数的，非常有用，但是其数据结构是json，探究一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class '_io.TextIOWrapper'>\n"
     ]
    }
   ],
   "source": [
    "d_dict = {\"first\":[1,2,3],\"second\":(4,5,6)}\n",
    "print(type(d_dict))\n",
    "with open(\"test.json\",\"w\") as f1:\n",
    "    print(type(f1))\n",
    "    json.dump(d_dict,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'second': [4, 5, 6], 'first': [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.json\",\"r\") as f1:\n",
    "    temp = json.load(f1)\n",
    "    print(type(temp))\n",
    "    print(temp)\n",
    "### 小结，就是存储数据的类型嘛，没什么好说的，到底有啥优点还木探究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试下是不是和视频中所述一样，更快的收敛了，然后尝试保存数据下次继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9243 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9445 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9401 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9507 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9479 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9507 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9508 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9546 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9457 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9553 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9504 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9501 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9482 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9574 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9505 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9555 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9523 / 10000\n"
     ]
    }
   ],
   "source": [
    "from src import mnist_loader\n",
    "from src import network2\n",
    "\n",
    "tra_d,val_d,tst_d = mnist_loader.load_data_wrapper()\n",
    "net1 = network2.Network([784,30,10],cost=network2.CrossEntropyCost)##这里的用法也要注意一下！\n",
    "net1.SGD(tra_d,20,10,1.0,lmbda=5.0,evaluation_data=val_d,monitor_evaluation_accuracy = True)\n",
    "net1.save(\"traing_reslut.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 网络好像是比network的快一点，可以保存参数以后从参数直接创建新的好的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net2 = network2.load(\"traing_reslut.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 有空的时候可以玩一玩，用训练好从参数，直接预测，今天就不搞了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'downsample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-04b3744c60cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mE:\\Git-repository\\neural-networks-and-deep-learning\\src\\network3.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshared_randomstreams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[1;31m# Activation functions for neurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'downsample'"
     ]
    }
   ],
   "source": [
    "from src import network3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 据推算，theano在2017-09-30日就不在更新了：https://blog.csdn.net/Lyrassongs/article/details/78158621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to run under a GPU.  If this is not desired, then modify network3.py\n",
      "to set the GPU flag to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "##将theano这个库退回到0.8.2后\n",
    "from src import network3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a CPU.  If this is not desired, then the modify network3.py to set\n",
      "the GPU flag to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from src import network3\n",
    "## 用这个不行，是因为我还没改用那个已经废弃的库呢：3-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 如何查看安装包的版本 https://blog.csdn.net/geerniya/article/details/78547673?locationNum=7&fps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pool_2d in module theano.tensor.signal.pool:\n",
      "\n",
      "pool_2d(input, ds, ignore_border=None, st=None, padding=(0, 0), mode='max')\n",
      "    Downscale the input by a specified factor\n",
      "    \n",
      "    Takes as input a N-D tensor, where N >= 2. It downscales the input image by\n",
      "    the specified factor, by keeping only the maximum value of non-overlapping\n",
      "    patches of size (ds[0],ds[1])\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    input : N-D theano tensor of input images\n",
      "        Input images. Max pooling will be done over the 2 last dimensions.\n",
      "    ds : tuple of length 2\n",
      "        Factor by which to downscale (vertical ds, horizontal ds).\n",
      "        (2,2) will halve the image in each dimension.\n",
      "    ignore_border : bool (default None, will print a warning and set to False)\n",
      "        When True, (5,5) input with ds=(2,2) will generate a (2,2) output.\n",
      "        (3,3) otherwise.\n",
      "    st : tuple of two ints\n",
      "        Stride size, which is the number of shifts over rows/cols to get the\n",
      "        next pool region. If st is None, it is considered equal to ds\n",
      "        (no overlap on pooling regions).\n",
      "    padding : tuple of two ints\n",
      "        (pad_h, pad_w), pad zeros to extend beyond four borders of the\n",
      "        images, pad_h is the size of the top and bottom margins, and\n",
      "        pad_w is the size of the left and right margins.\n",
      "    mode : {'max', 'sum', 'average_inc_pad', 'average_exc_pad'}\n",
      "        Operation executed on each window. `max` and `sum` always exclude\n",
      "        the padding in the computation. `average` gives you the choice to\n",
      "        include or exclude it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from theano.tensor.signal.pool import pool_2d\n",
    "help(pool_2d)##默认是输出最大池化值的，用这个试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a CPU.  If this is not desired, then the modify network3.py to set\n",
      "the GPU flag to True.\n"
     ]
    }
   ],
   "source": [
    "from src import network3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tra_d,val_d,tst_d = network3.load_data_shared(\"E:\\\\Git-repository\\\\neural-networks-and-deep-learning\\\\data\\\\mnist.pkl.gz\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> 2 <class 'theano.tensor.sharedvar.TensorSharedVariable'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 2. 3.]\n",
      "<class 'theano.tensor.sharedvar.TensorSharedVariable'>\n",
      "<TensorType(float32, matrix)>\n",
      "<class 'theano.tensor.sharedvar.TensorSharedVariable'>\n",
      "<TensorType(float32, vector)>\n"
     ]
    }
   ],
   "source": [
    "## 3-1 \n",
    "import numpy as np\n",
    "import theano\n",
    "print(type(tra_d),len(tra_d),type(tra_d[0]))\n",
    "temp_d = ([[1,2,3],[4,5,6],[7,8,9]],[1.0,2.0,3.0])##模拟刚刚读出的数据\n",
    "temp1 = np.asarray(temp_d[0],dtype=theano.config.floatX)\n",
    "print(type(temp1))\n",
    "print(temp1)\n",
    "temp2 = np.asarray(temp_d[1],dtype=theano.config.floatX)\n",
    "print(type(temp2))\n",
    "print(temp2)\n",
    "temp_1 = theano.shared(temp1,borrow=True)\n",
    "print(type(temp_1))\n",
    "print(temp_1)\n",
    "temp_2 = theano.shared(temp2,borrow=True)\n",
    "print(type(temp_2))\n",
    "print(temp_2)\n",
    "## 不知道具体他对数据做了什么，只知道是一个数据处理过程，但是也没必要关心了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\tensor\\nnet\\conv.py:98: UserWarning: theano.tensor.nnet.conv.conv2d is deprecated. Use theano.tensor.nnet.conv2d instead.\n",
      "  warnings.warn(\"theano.tensor.nnet.conv.conv2d is deprecated.\"\n",
      "E:\\Git-repository\\neural-networks-and-deep-learning\\src\\network3.py:233: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  pooled_out = pool.pool_2d(input=conv_out, ds=self.poolsize, ignore_border=True)\n"
     ]
    }
   ],
   "source": [
    "## 里面用到了大量的库，哎~先跑下试试吧\n",
    "mini_batch_size=10\n",
    "net3 = network3.Network([\n",
    "        network3.ConvPoolLayer(image_shape=(mini_batch_size,1,28,28),\n",
    "                              filter_shape=(20,1,5,5),\n",
    "                              poolsize=(2,2)),\n",
    "        network3.FullyConnectedLayer(n_in=20*12*12,n_out=100),\n",
    "        network3.SoftmaxLayer(n_in=100,n_out=10)],mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-950c812f8781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtra_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtst_d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mE:\\Git-repository\\neural-networks-and-deep-learning\\src\\network3.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mbest_validation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[1;32mfor\u001b[0m \u001b[0mminibatch_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_training_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_training_batches\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "net3.SGD(tra_d,10,mini_batch_size,0.1,val_d,tst_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "## 一个整型除于另一个整型居然是个float，所以用\"//\"再试一下\n",
    "print(tra_d[0].get_value(borrow=True).shape[0])\n",
    "print(tra_d[0].get_value(borrow=True).shape[0]//mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 93.74%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 93.05%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-950c812f8781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtra_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtst_d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mE:\\Git-repository\\neural-networks-and-deep-learning\\src\\network3.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     validation_accuracy = np.mean(\n\u001b[0;32m--> 169\u001b[0;31m                         [validate_mb_accuracy(j) for j in range(num_validation_batches)])\n\u001b[0m\u001b[1;32m    170\u001b[0m                     print(\"Epoch {0}: validation accuracy {1:.2%}\".format(\n\u001b[1;32m    171\u001b[0m                         epoch, validation_accuracy))\n",
      "\u001b[0;32mE:\\Git-repository\\neural-networks-and-deep-learning\\src\\network3.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     validation_accuracy = np.mean(\n\u001b[0;32m--> 169\u001b[0;31m                         [validate_mb_accuracy(j) for j in range(num_validation_batches)])\n\u001b[0m\u001b[1;32m    170\u001b[0m                     print(\"Epoch {0}: validation accuracy {1:.2%}\".format(\n\u001b[1;32m    171\u001b[0m                         epoch, validation_accuracy))\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 for thunk, node, old_storage in zip(self.thunks, self.nodes,\n\u001b[1;32m    300\u001b[0m                                                     self.post_thunk_clear):\n\u001b[0;32m--> 301\u001b[0;31m                     \u001b[0mthunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mold_s\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mold_storage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                         \u001b[0mold_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, params)\u001b[0m\n\u001b[1;32m    899\u001b[0m             def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    900\u001b[0m                      params=params_val):\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\tensor\\signal\\pool.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out, params)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpool_out_shp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                 zzk[r] = func(\n\u001b[0;32m--> 574\u001b[0;31m                     yk[[region_slices[i][r[i]] for i in xrange(nd)]])\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minfer_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;31m# small reductions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net3.SGD(tra_d,10,mini_batch_size,0.1,val_d,tst_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "temp = {\"layers\":net3.layers}\n",
    "#with open(\"convnn.json\",\"w\") as f:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prod in module numpy.core.fromnumeric:\n",
      "\n",
      "prod(a, axis=None, dtype=None, out=None, keepdims=<class 'numpy._globals._NoValue'>)\n",
      "    Return the product of array elements over a given axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which a product is performed.  The default,\n",
      "        axis=None, will calculate the product of all the elements in the\n",
      "        input array. If axis is negative it counts from the last to the\n",
      "        first axis.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If axis is a tuple of ints, a product is performed on all of the\n",
      "        axes specified in the tuple instead of a single axis or all the\n",
      "        axes as before.\n",
      "    dtype : dtype, optional\n",
      "        The type of the returned array, as well as of the accumulator in\n",
      "        which the elements are multiplied.  The dtype of `a` is used by\n",
      "        default unless `a` has an integer dtype of less precision than the\n",
      "        default platform integer.  In that case, if `a` is signed then the\n",
      "        platform integer is used while if `a` is unsigned then an unsigned\n",
      "        integer of the same precision as the platform integer is used.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output, but the type of the output\n",
      "        values will be cast if necessary.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left in the\n",
      "        result as dimensions with size one. With this option, the result\n",
      "        will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `prod` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-classes `sum` method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    product_along_axis : ndarray, see `dtype` parameter above.\n",
      "        An array shaped as `a` but with the specified axis removed.\n",
      "        Returns a reference to `out` if specified.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.prod : equivalent method\n",
      "    numpy.doc.ufuncs : Section \"Output arguments\"\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Arithmetic is modular when using integer types, and no error is\n",
      "    raised on overflow.  That means that, on a 32-bit platform:\n",
      "    \n",
      "    >>> x = np.array([536870910, 536870910, 536870910, 536870910])\n",
      "    >>> np.prod(x)  # random\n",
      "    16\n",
      "    \n",
      "    The product of an empty array is the neutral element 1:\n",
      "    \n",
      "    >>> np.prod([])\n",
      "    1.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    By default, calculate the product of all elements:\n",
      "    \n",
      "    >>> np.prod([1.,2.])\n",
      "    2.0\n",
      "    \n",
      "    Even when the input array is two-dimensional:\n",
      "    \n",
      "    >>> np.prod([[1.,2.],[3.,4.]])\n",
      "    24.0\n",
      "    \n",
      "    But we can also specify the axis over which to multiply:\n",
      "    \n",
      "    >>> np.prod([[1.,2.],[3.,4.]], axis=1)\n",
      "    array([  2.,  12.])\n",
      "    \n",
      "    If the type of `x` is unsigned, then the output type is\n",
      "    the unsigned platform integer:\n",
      "    \n",
      "    >>> x = np.array([1, 2, 3], dtype=np.uint8)\n",
      "    >>> np.prod(x).dtype == np.uint\n",
      "    True\n",
      "    \n",
      "    If `x` is of a signed integer type, then the output type\n",
      "    is the default platform integer:\n",
      "    \n",
      "    >>> x = np.array([1, 2, 3], dtype=np.int8)\n",
      "    >>> np.prod(x).dtype == int\n",
      "    True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[2,3],[5,6]])\n",
    "np.prod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 18])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(x,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 小结：\n",
    "prod函数，返回的是矩阵所有元素的乘积，当指定特定维度的时候，也可以算出特定维度的乘积，axis=0：列内相乘；axis=1：行内相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*25/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sum([(i**2).sum() for i in x])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4+9+25+36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[0,0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import theano as TH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function shared in module theano.compile.sharedvalue:\n",
      "\n",
      "shared(value, name=None, strict=False, allow_downcast=None, **kwargs)\n",
      "    Return a SharedVariable Variable, initialized with a copy or\n",
      "    reference of `value`.\n",
      "    \n",
      "    This function iterates over constructor functions to find a\n",
      "    suitable SharedVariable subclass.  The suitable one is the first\n",
      "    constructor that accept the given value.  See the documentation of\n",
      "    :func:`shared_constructor` for the definition of a constructor\n",
      "    function.\n",
      "    \n",
      "    This function is meant as a convenient default.  If you want to use a\n",
      "    specific shared variable constructor, consider calling it directly.\n",
      "    \n",
      "    ``theano.shared`` is a shortcut to this function.\n",
      "    \n",
      "    .. attribute:: constructors\n",
      "    \n",
      "    A list of shared variable constructors that will be tried in reverse\n",
      "    order.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    By passing kwargs, you effectively limit the set of potential constructors\n",
      "    to those that can accept those kwargs.\n",
      "    \n",
      "    Some shared variable have ``borrow`` as extra kwargs.\n",
      "    `See <http://deeplearning.net/software/theano/tutorial/aliasing.    html#borrowing-when-creating-shared-variables>`_ for details.\n",
      "    \n",
      "    Some shared variable have ``broadcastable`` as extra kwargs. As shared\n",
      "    variable shapes can change, all dimensions default to not being\n",
      "    broadcastable, even if ``value`` has a shape of 1 along some dimension.\n",
      "    This parameter allows you to create for example a `row` or `column` 2d\n",
      "    tensor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TH.shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cast in module theano.tensor.basic:\n",
      "\n",
      "cast(x, dtype)\n",
      "    Symbolically cast `x` to a Tensor of type `dtype`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TH.tensor.cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
